<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Fake News Detection</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Poppins', sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #7e22ce 100%);
            min-height: 100vh;
            padding: 20px;
            position: relative;
            overflow-x: hidden;
        }

        body::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: 
                radial-gradient(circle at 20% 50%, rgba(120, 119, 198, 0.3) 0%, transparent 50%),
                radial-gradient(circle at 80% 80%, rgba(138, 43, 226, 0.3) 0%, transparent 50%);
            pointer-events: none;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            position: relative;
            z-index: 1;
        }

        .header {
            text-align: center;
            color: white;
            margin-bottom: 40px;
            padding: 30px 20px;
            animation: fadeInDown 0.8s ease-out;
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .header h1 {
            font-size: 3em;
            margin-bottom: 15px;
            font-weight: 700;
            background: linear-gradient(45deg, #fff, #a78bfa);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .card {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 45px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3), 0 0 0 1px rgba(255,255,255,0.2);
            margin-bottom: 30px;
            animation: fadeInUp 0.8s ease-out 0.2s both;
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        h2 {
            color: #7c3aed;
            margin-top: 35px;
            margin-bottom: 18px;
            font-size: 2em;
            font-weight: 700;
            border-left: 5px solid #7c3aed;
            padding-left: 15px;
        }

        h3 {
            color: #5b21b6;
            margin-top: 25px;
            margin-bottom: 12px;
            font-size: 1.4em;
            font-weight: 600;
        }

        p {
            line-height: 1.6;
            color: #333;
            margin-bottom: 15px;
        }

        ul {
            margin-left: 20px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 10px;
            line-height: 1.6;
        }

        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            margin-top: 18px;
        }

        .tech-badge {
            background: linear-gradient(135deg, #7c3aed 0%, #5b21b6 100%);
            color: white;
            padding: 10px 20px;
            border-radius: 25px;
            font-size: 0.95em;
            font-weight: 600;
            box-shadow: 0 4px 12px rgba(124, 58, 237, 0.3);
            transition: all 0.3s;
        }

        .tech-badge:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 18px rgba(124, 58, 237, 0.5);
        }

        .btn-back {
            display: inline-block;
            background: linear-gradient(135deg, #7c3aed 0%, #5b21b6 100%);
            color: white;
            padding: 14px 35px;
            border-radius: 12px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s;
            margin-top: 25px;
            box-shadow: 0 8px 20px rgba(124, 58, 237, 0.3);
        }

        .btn-back:hover {
            transform: translateY(-3px);
            box-shadow: 0 12px 30px rgba(124, 58, 237, 0.5);
        }

        .footer {
            text-align: center;
            color: white;
            margin-top: 30px;
            opacity: 0.9;
        }

        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .feature-card {
            background: linear-gradient(135deg, #f3f4f6 0%, #e5e7eb 100%);
            padding: 25px;
            border-radius: 15px;
            border-left: 5px solid #7c3aed;
            box-shadow: 0 4px 12px rgba(0,0,0,0.05);
            transition: all 0.3s;
        }

        .feature-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 20px rgba(124, 58, 237, 0.2);
        }

        .feature-card h4 {
            color: #7c3aed;
            margin-bottom: 12px;
            font-size: 1.2em;
            font-weight: 600;
        }

        .nav-links {
            text-align: center;
            margin-top: 20px;
        }

        .nav-links a {
            color: white;
            text-decoration: none;
            margin: 0 15px;
            font-weight: 500;
            transition: all 0.3s;
            padding: 8px 16px;
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
        }

        .nav-links a:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>About the Project</h1>
            <div class="nav-links">
                <a href="/">üè† Home</a>
                <a href="/about">‚ÑπÔ∏è About</a>
                <a href="https://github.com/Ujjwal-eng/fake_news_detection" target="_blank">üíª GitHub</a>
            </div>
        </div>

        <div class="card">
            <h2>üéØ Project Overview</h2>
            <p>
                This Fake News Detection system is a machine learning-powered web application designed to help identify 
                potentially misleading or false news articles. Using Natural Language Processing (NLP) and advanced 
                ensemble machine learning algorithms, the system analyzes text content and provides predictions about its authenticity.
            </p>
            <p>
                <strong>Training Data:</strong> The models are trained on <strong>11,632 professionally labeled articles</strong> 
                spanning 2016-2023, covering political news, COVID-19 misinformation, and recent fake news from diverse sources. 
                This multi-year dataset ensures robust performance across different news contexts and writing styles.
            </p>

            <h2>‚ú® Key Features</h2>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>ü§ñ Ensemble ML Models</h4>
                    <p>4 algorithms (Naive Bayes, Random Forest, Logistic Regression, SVM) with majority voting</p>
                </div>
                <div class="feature-card">
                    <h4>ÔøΩ AI Fact-Checker</h4>
                    <p>Entity verification via Wikipedia, numerical validation, and scam pattern detection</p>
                </div>
                <div class="feature-card">
                    <h4>üìä Real-time Analysis</h4>
                    <p>Instant classification with confidence scores (83-90% accuracy) and detailed insights</p>
                </div>
                <div class="feature-card">
                    <h4>üß† Advanced NLP</h4>
                    <p>Text preprocessing with tokenization, stemming, and TF-IDF vectorization (5,000 features)</p>
                </div>
                <div class="feature-card">
                    <h4>üé® Modern Interface</h4>
                    <p>Clean, responsive web interface with dark/light themes and detailed analytics</p>
                </div>
                <div class="feature-card">
                    <h4>ÔøΩÔ∏è Smart Validation</h4>
                    <p>Handles edge cases: URLs, non-English text, and invalid inputs with helpful error messages</p>
                </div>
            </div>

            <h2>üõ†Ô∏è Technology Stack</h2>
            <div class="tech-stack">
                <span class="tech-badge">Python</span>
                <span class="tech-badge">Flask</span>
                <span class="tech-badge">scikit-learn</span>
                <span class="tech-badge">NLTK</span>
                <span class="tech-badge">spaCy</span>
                <span class="tech-badge">Wikipedia API</span>
                <span class="tech-badge">Pandas</span>
                <span class="tech-badge">NumPy</span>
                <span class="tech-badge">HTML/CSS</span>
                <span class="tech-badge">JavaScript</span>
            </div>

            <h2>üß† How It Works</h2>
            <h3>1. Text Preprocessing</h3>
            <ul>
                <li>Tokenization: Breaking down text into individual words</li>
                <li>Lowercasing: Converting all text to lowercase for consistency</li>
                <li>Stop word removal: Eliminating common words that don't add meaning</li>
                <li>Stemming/Lemmatization: Reducing words to their root form</li>
            </ul>

            <h3>2. Feature Extraction</h3>
            <ul>
                <li>TF-IDF Vectorization: Converting text into numerical features</li>
                <li>N-gram analysis: Capturing word patterns and phrases</li>
                <li>Feature selection: Identifying the most informative features</li>
            </ul>

            <h3>3. Machine Learning Classification</h3>
            <ul>
                <li>Multiple ML algorithms trained on labeled news datasets</li>
                <li>Ensemble methods for improved accuracy</li>
                <li>Probability estimation for confidence scoring</li>
            </ul>

            <h3>4. AI Fact-Checker (NEW!)</h3>
            <p>
                Our advanced fact-checking layer adds a second line of defense by verifying content accuracy, 
                not just writing patterns. This helps catch sophisticated fake news that mimics professional journalism.
            </p>
            <ul>
                <li><strong>Entity Extraction:</strong> Uses spaCy NLP to identify organizations, locations, dates, and infrastructure mentioned in articles</li>
                <li><strong>Wikipedia Verification:</strong> Cross-references entities with Wikipedia to check if they exist and match the context</li>
                <li><strong>Numerical Validation:</strong> Detects unrealistic claims (e.g., impossible percentages >100%, unrealistic distances/speeds)</li>
                <li><strong>Scam Pattern Detection:</strong> Identifies viral message patterns like "forward this", "share urgently", "before it's deleted"</li>
                <li><strong>Confidence Override:</strong> Automatically classifies articles as FAKE when verifiable false claims are detected, even if writing style appears professional</li>
            </ul>
            <p>
                <strong>Example:</strong> If an article claims "Delhi Metro opened a 600km line to Mars yesterday" with professional writing, 
                the ML models might classify it as REAL based on style. However, the fact-checker will detect the impossible distance 
                and non-existent infrastructure, overriding the prediction to FAKE NEWS.
            </p>

            <h2>üìà Model Performance</h2>
            <p>
                The models have been trained on <strong>11,632 diverse news articles (2016-2023)</strong> and evaluated using standard metrics:
            </p>
            <ul>
                <li><strong>Naive Bayes:</strong> 83.2% accuracy - Fast baseline classifier</li>
                <li><strong>Logistic Regression:</strong> 90.0% accuracy - Best overall performer</li>
                <li><strong>Random Forest:</strong> 87.8% accuracy - Robust ensemble method</li>
                <li><strong>SVM:</strong> 89.7% accuracy - High precision classifier</li>
            </ul>
            <p><strong>Ensemble System:</strong> All 4 models vote together using majority voting with confidence-based tie-breaking for optimal predictions.</p>
            
            <h3>üìä Dataset Coverage</h3>
            <ul>
                <li><strong>2016-2017:</strong> Political news from ISOT dataset (44,898 articles ‚Üí 5,816 selected)</li>
                <li><strong>2020-2021:</strong> COVID-19 fake news and health misinformation (3,581 articles)</li>
                <li><strong>2022-2023:</strong> Recent fake news from multiple sources (6,299 articles)</li>
                <li><strong>Total Training Set:</strong> 11,632 articles (50% real, 50% fake) after deduplication</li>
            </ul>
            
            <h3>üìè Evaluation Metrics</h3>
            <ul>
                <li><strong>Accuracy:</strong> Overall correctness of predictions (83-90%)</li>
                <li><strong>Precision:</strong> Accuracy of positive predictions (83-90%)</li>
                <li><strong>Recall:</strong> Ability to find all positive instances (83-90%)</li>
                <li><strong>F1-Score:</strong> Harmonic mean of precision and recall (83-90%)</li>
            </ul>

            <h2>‚ö†Ô∏è Important Notes</h2>
            <ul>
                <li><strong>Dual-Layer System:</strong> Combines ML pattern detection with AI fact-checking for comprehensive analysis</li>
                <li><strong>Educational Tool:</strong> Assists in identifying potentially fake news but always verify through multiple sources</li>
                <li><strong>Fact-Checker Coverage:</strong> Wikipedia-based verification works best for well-documented entities; may not catch very recent or obscure claims</li>
                <li><strong>English Only:</strong> Current version supports English text only; non-English input will be rejected with helpful error messages</li>
                <li><strong>Training Period:</strong> Models trained on 2016-2023 data (most recent professionally labeled datasets available)</li>
                <li><strong>Input Validation:</strong> System validates inputs and rejects URLs-only, very short text, and special characters-only submissions</li>
                <li><strong>Context Matters:</strong> Source credibility, publication date, and expert analysis remain crucial for news verification</li>
            </ul>
            
            <h3>üéì Real-World ML Understanding</h3>
            <p>This project demonstrates important machine learning concepts:</p>
            <ul>
                <li><strong>Temporal Dataset Drift:</strong> Understanding how model performance varies with time</li>
                <li><strong>Data Quality vs Quantity:</strong> 11,632 professionally labeled articles beat millions of unlabeled ones</li>
                <li><strong>Balanced Training:</strong> 50/50 split prevents bias toward predicting one class</li>
                <li><strong>Ensemble Methods:</strong> Combining multiple models for better predictions</li>
                <li><strong>Real-World Constraints:</strong> Working within data availability limitations</li>
            </ul>

            <h2>üöÄ Future Enhancements</h2>
            <ul>
                <li><strong>Deep Learning:</strong> LSTM, BERT, and Transformer models for improved accuracy</li>
                <li><strong>Enhanced Fact-Checking:</strong> Real-time APIs from Alt News, BOOM Live, Snopes for additional verification</li>
                <li><strong>Multi-language Support:</strong> Hindi, Spanish, French, and other languages</li>
                <li><strong>Source Analysis:</strong> Credibility scoring based on publisher reputation and domain analysis</li>
                <li><strong>Real-time Monitoring:</strong> Continuous news feed analysis and alerts</li>
                <li><strong>Browser Extension:</strong> Instant verification while browsing</li>
                <li><strong>Temporal Updates:</strong> Automatic retraining with 2024+ data as it becomes available</li>
                <li><strong>Mobile App:</strong> iOS and Android applications for on-the-go verification</li>
                <li><strong>URL Content Extraction:</strong> Automatic web scraping to analyze article content from URLs</li>
            </ul>

            <h2>üë®‚Äçüíª Developer</h2>
            <p>
                This project was developed as a comprehensive machine learning portfolio project to demonstrate skills in:
            </p>
            <ul>
                <li><strong>Natural Language Processing:</strong> Text preprocessing, tokenization, stemming, TF-IDF vectorization, Named Entity Recognition (NER)</li>
                <li><strong>Machine Learning:</strong> Multiple algorithms, ensemble methods, model evaluation and optimization</li>
                <li><strong>AI Systems:</strong> Fact-checking with spaCy NER, Wikipedia API integration, pattern detection algorithms</li>
                <li><strong>Data Engineering:</strong> Dataset collection, cleaning, balancing, and feature engineering</li>
                <li><strong>Web Development:</strong> Flask backend, responsive frontend, RESTful API design</li>
                <li><strong>ML Best Practices:</strong> Train/test splitting, cross-validation, performance metrics, input validation</li>
                <li><strong>Real-World Constraints:</strong> Understanding temporal drift, data availability, and labeling challenges</li>
            </ul>
            
            <h3>üìä Project Highlights</h3>
            <ul>
                <li>‚úÖ <strong>11,632 labeled articles</strong> from 3 major datasets (ISOT, COVID-19, Recent)</li>
                <li>‚úÖ <strong>4 ML algorithms</strong> with ensemble voting system</li>
                <li>‚úÖ <strong>AI Fact-Checker</strong> with Wikipedia verification and scam detection</li>
                <li>‚úÖ <strong>83-90% accuracy</strong> across all models</li>
                <li>‚úÖ <strong>Smart input validation</strong> with edge case handling</li>
                <li>‚úÖ <strong>Perfect data balance</strong> (50/50 real/fake split)</li>
                <li>‚úÖ <strong>7-year coverage</strong> (2016-2023) for temporal robustness</li>
                <li>‚úÖ <strong>Production-ready</strong> Flask web application with modern UI</li>
            </ul>

            <h2>üìû Connect</h2>
            <p>
                <strong>GitHub:</strong> <a href="https://github.com/Ujjwal-eng/fake_news_detection" target="_blank" style="color: #667eea;">github.com/Ujjwal-eng/fake_news_detection</a>
            </p>

            <a href="/" class="btn-back">‚Üê Back to Home</a>
        </div>

        <div class="footer">
            <p>Built with Machine Learning ‚Ä¢ NLP ‚Ä¢ AI Fact-Checking ‚Ä¢ Python ‚Ä¢ Flask ‚Ä¢ scikit-learn ‚Ä¢ spaCy</p>
            <p style="margin-top: 10px;">¬© 2025 Fake News Detection Project | Developed by Ujjwal Bansal</p>
        </div>
    </div>
</body>
</html>
