# üîç Fake News Detection System

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)](https://flask.palletsprojects.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-orange)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An AI-powered web application that uses Natural Language Processing (NLP) and Machine Learning to detect fake news articles with high accuracy. This project demonstrates end-to-end ML model development, from data preprocessing to web deployment.

## üåü Features

- **ü§ñ Ensemble ML Models**: 4 models (Naive Bayes, Random Forest, Logistic Regression, SVM) with majority voting
- **üîç AI Fact-Checker**: Entity verification via Wikipedia, numerical claim validation, scam pattern detection
- **üåê Google Fact Check API** (Optional): Professional fact-checking from Snopes, PolitiFact, and other verified sources
- **üß† Advanced NLP**: Text preprocessing with tokenization, stemming, stopword removal, and TF-IDF vectorization
- **üé® Modern Web Interface**: Beautiful, responsive Flask-based UI with dark/light themes
- **‚ö° Real-time Analysis**: Instant classification with confidence scores and detailed insights
- **üìä Comprehensive Analytics**: Probability distributions, model performance metrics, and fact-check warnings
- **üõ°Ô∏è Input Validation**: Smart edge case handling for URLs, non-English text, and invalid inputs
- **üß™ Thorough Testing**: Unit tests, model evaluation suite, and edge case analysis

## üìÅ Project Structure

```
fake-news-detection/
‚îú‚îÄ‚îÄ app.py                 # Flask web application
‚îú‚îÄ‚îÄ config.py              # Configuration settings
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ README.md             # Project documentation
‚îú‚îÄ‚îÄ .gitignore            # Git ignore rules
‚îú‚îÄ‚îÄ templates/            # HTML templates
‚îÇ   ‚îú‚îÄ‚îÄ index.html        # Main page
‚îÇ   ‚îî‚îÄ‚îÄ about.html        # About page
‚îú‚îÄ‚îÄ src/                  # Source code modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_processing.py # NLP preprocessing utilities
‚îÇ   ‚îú‚îÄ‚îÄ model.py          # ML model implementation
‚îÇ   ‚îú‚îÄ‚îÄ fact_checker.py   # AI fact-checking module (NEW!)
‚îÇ   ‚îî‚îÄ‚îÄ utils.py          # Helper functions
‚îú‚îÄ‚îÄ data/                 # Dataset storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Raw datasets
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Processed datasets
‚îÇ   ‚îî‚îÄ‚îÄ sample_data.csv   # Sample dataset
‚îú‚îÄ‚îÄ models/               # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes_model.joblib
‚îÇ   ‚îú‚îÄ‚îÄ vectorizer.joblib
‚îÇ   ‚îî‚îÄ‚îÄ training_results.txt
‚îú‚îÄ‚îÄ notebooks/            # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ data_exploration.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ text_processing_basics.ipynb
‚îî‚îÄ‚îÄ tests/                # Unit tests
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ test_model.py
```

## üöÄ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Git (for cloning)

### Step 1: Clone the Repository
```bash
git clone https://github.com/Ujjwal-eng/fake_news_detection.git
cd fake_news_detection
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Download Required NLTK Data & spaCy Model
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('omw-1.4')"
python -m spacy download en_core_web_sm
```

### Step 5: (Optional) Configure Google Fact Check API
For enhanced fact-checking from professional sources like Snopes and PolitiFact:

1. **Get a free API key**:
   - Follow the detailed setup guide: [GOOGLE_API_SETUP.md](GOOGLE_API_SETUP.md)
   - Free tier includes **10,000 requests per day** at no cost

2. **Add API key to environment**:
   ```bash
   # Windows PowerShell
   $env:GOOGLE_FACT_CHECK_API_KEY="your_google_api_key_here"
   
   # Windows Command Prompt
   set GOOGLE_FACT_CHECK_API_KEY=your_google_api_key_here
   
   # Linux/Mac
   export GOOGLE_FACT_CHECK_API_KEY="your_google_api_key_here"
   ```

3. **Or add to shell profile** (permanent):
   ```bash
   # Linux/Mac - add to ~/.bashrc or ~/.zshrc
   echo 'export GOOGLE_FACT_CHECK_API_KEY="your_key_here"' >> ~/.bashrc
   source ~/.bashrc
   
   # Windows - use System Environment Variables (GUI)
   # Settings ‚Üí System ‚Üí About ‚Üí Advanced system settings ‚Üí Environment Variables
   ```

**Note**: The app works perfectly without the Google API using Wikipedia + pattern matching. The Google API is an optional enhancement that provides fact-checks from professional fact-checkers.

### Step 6: Run the Application
```bash
python app.py
```
Then open your browser and navigate to: `http://localhost:5000`

### Training Models
To train new models with custom dataset:
```bash
# Place dataset in data/raw/
# Then run the training script
python -m src.model
```

### Using Jupyter Notebooks
For experimentation and analysis:
```bash
jupyter notebook
# Open notebooks/ directory
```

## üìä Dataset

### Training Data Coverage (2016-2023)
The models are trained on **11,632 professionally labeled articles** spanning multiple years and contexts:

- **2016-2017**: Political news from ISOT Fake News Dataset (5,816 articles)
- **2020-2021**: COVID-19 misinformation and health news (3,581 articles)
- **2022-2023**: Recent fake news from diverse sources (6,299 articles)

**Dataset Composition:**
- Real News: 5,816 articles (50%)
- Fake News: 5,816 articles (50%)
- Total: 11,632 perfectly balanced articles

### Why 2016-2023?
Labeled fake news datasets require:
- ‚úÖ Professional fact-checking (6-12 months)
- ‚úÖ Expert verification from multiple sources
- ‚úÖ Legal review to avoid defamation
- ‚úÖ Consensus from fact-checking organizations

This makes 2016-2023 the most recent professionally verified data available for training.

### Required Format
```csv
text,label
"News article text here...",0
"Another news article...",1
```

- **text**: The news article content (string)
- **label**: 0 for real news, 1 for fake news (integer)

## üéØ Model Performance

Trained on **11,632 balanced articles (2016-2023)**:

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Naive Bayes | 83.2% | 83.7% | 83.2% | 83.1% |
| Logistic Regression | 90.0% | 90.0% | 90.0% | 90.0% |
| Random Forest | 87.8% | 87.9% | 87.8% | 87.8% |
| SVM | 89.7% | 89.7% | 89.7% | 89.7% |

**Ensemble Voting System:** Combines all 4 models with majority voting and confidence-based tie-breaking for optimal accuracy.

### Dataset Sources
- **ISOT Fake News Dataset**: 44,898 political articles (2016-2017) from Kaggle
- **COVID-19 Fake News Dataset**: 10,700 health-related articles (2020-2021)
- **Recent Fake News Dataset**: 6,335 diverse articles (2022-2023)

*Final training set: 11,632 articles after deduplication and balancing*

## üõ†Ô∏è Technologies Used

### Core Technologies
- **Python 3.8+**: Primary programming language
- **Flask**: Web framework for the application
- **scikit-learn**: Machine learning models and evaluation
- **NLTK**: Natural language processing toolkit
- **Pandas & NumPy**: Data manipulation and analysis
- **Joblib**: Model serialization

### Machine Learning
- Naive Bayes Classifier
- Random Forest Classifier
- Logistic Regression
- Support Vector Machine (SVM)
- TF-IDF Vectorization

### Frontend
- HTML5 & CSS3
- JavaScript (Vanilla)
- Responsive Design

## üß† How It Works

### 1. Text Preprocessing Pipeline
```
Raw Text ‚Üí Lowercasing ‚Üí Tokenization ‚Üí Stop Word Removal ‚Üí Stemming ‚Üí Clean Text
```

### 2. Feature Extraction
- **TF-IDF Vectorization**: Converts text to numerical features
- **N-gram Analysis**: Captures word patterns (unigrams, bigrams)
- **Feature Selection**: Identifies most informative features

### 3. Classification
- Multiple ML models trained on labeled datasets
- Ensemble predictions for improved accuracy
- Probability estimation for confidence scoring

### 4. Web Interface
- User submits news text
- Backend processes and vectorizes text
- Model predicts and returns result with confidence

## üéì Key Learnings & Skills Demonstrated

- ‚úÖ End-to-end ML project development
- ‚úÖ Natural Language Processing techniques
- ‚úÖ Model training, evaluation, and optimization
- ‚úÖ Web application development with Flask
- ‚úÖ RESTful API design
- ‚úÖ Version control with Git/GitHub
- ‚úÖ Code organization and best practices

## üì∏ Screenshots

### Home Page
Clean and intuitive interface for news analysis

### Results Page
Detailed prediction with confidence scores and probabilities

## üîÆ Future Enhancements

- [ ] Deep learning models (LSTM, BERT, Transformers)
- [ ] Multi-language support (Hindi, Spanish, etc.)
- [ ] Source credibility analysis
- [ ] Real-time news monitoring and alerts
- [ ] Browser extension for instant verification
- [ ] Mobile application (iOS/Android)
- [ ] Integration with fact-checking APIs (Alt News, BOOM Live)
- [ ] User authentication and history tracking
- [ ] Temporal model updates with 2024+ data as it becomes available

## ‚ö†Ô∏è Disclaimer & Limitations

### Use Responsibly
This system is designed as an **educational tool and ML demonstration project**. It should not be used as the sole method for verifying news authenticity.

### Three-Tier Verification System

#### Tier 1: Google Fact Check API (Optional)
Professional fact-checking from verified sources:
- ‚úÖ **Verified Sources**: Checks against Snopes, PolitiFact, FactCheck.org, and 100+ fact-checkers
- ‚úÖ **ClaimReview Database**: Access to Google's ClaimReview structured data from trusted publishers
- ‚úÖ **Claim Matching**: Searches for similar claims fact-checked by professionals
- ‚úÖ **Expert Verdicts**: Returns fact-checker ratings (TRUE, FALSE, MIXTURE, UNVERIFIED)

**How it works**: If Google API finds matching fact-checks, it displays professional verdicts with source links, providing the most authoritative verification available.

#### Tier 2: AI Fact-Checker
Content verification and claim validation:
- ‚úÖ **Entity Verification**: Cross-references organizations, locations, and infrastructure with Wikipedia
- ‚úÖ **Numerical Validation**: Detects unrealistic claims (impossible percentages, distances, speeds)
- ‚úÖ **Scam Pattern Detection**: Identifies viral message patterns ("forward this", "share urgently")
- ‚úÖ **Confidence Override**: Automatically flags articles with verifiable false claims as FAKE

**How it works**: If the fact-checker detects contradictions (e.g., non-existent metro lines, impossible statistics), it **overrides the ML prediction** and classifies the article as FAKE NEWS, even if the writing style appears professional.

#### Tier 3: Machine Learning Models
Pattern analysis of **writing style and linguistic features**:
- ‚úÖ Sensational language and emotional manipulation
- ‚úÖ Conspiracy theory rhetoric patterns
- ‚úÖ Poor grammar and structure (common in low-quality fake news)
- ‚úÖ Clickbait-style headlines
- ‚úÖ Absence of proper attribution and sources
- ‚úÖ Vague or missing details

### What the System CANNOT Detect
Despite the three-tier approach, some limitations remain:
- ‚ùå Cannot verify claims not yet fact-checked by professional organizations (for Google API tier)
- ‚ùå Cannot verify very recent events not yet documented on Wikipedia (for AI fact-checker tier)
- ‚ùå Cannot access paywalled sources or private databases
- ‚ùå Limited to English language content
- ‚ùå Cannot verify claims requiring real-time data or government databases

**Example**: A fake news article about a non-existent Delhi Metro line, written in professional journalistic style with specific details, would be caught by the AI fact-checker (Tier 2) which verifies infrastructure claims against Wikipedia, or by Google API (Tier 1) if fact-checkers have already debunked it.

**Solution**: The three-tier system provides comprehensive verification:
1. **Tier 1 (Google API)**: Professional fact-checker verdicts from trusted sources
2. **Tier 2 (AI Fact-Checker)**: Wikipedia verification + pattern detection
3. **Tier 3 (ML Models)**: Writing style and linguistic pattern analysis

See [MODEL_LIMITATIONS.md](MODEL_LIMITATIONS.md) for detailed analysis.

### Temporal Limitations
- **Training Period**: 2016-2023 (most recent professionally labeled data)
- **Performance**: Optimized for news from the training period
- **Modern Terms**: May have limited exposure to very recent terminology (2024-2025 specific events/technologies)

### Best Practices
Always:
- ‚úÖ Cross-reference with multiple reliable sources
- ‚úÖ Check the original source's credibility and reputation
- ‚úÖ Consider the context, date, and author of publication
- ‚úÖ Consult professional fact-checkers for important decisions
- ‚úÖ Verify through established fact-checking organizations

### Real-World Context
This project demonstrates understanding of:
- Data labeling challenges in ML
- Temporal dataset drift and model limitations
- Professional ML project development
- Real-world constraints in fake news detection

## üë®‚Äçüíª Author

**Ujjwal Bansal**
- GitHub: [@Ujjwal-eng](https://github.com/Ujjwal-eng)
- Project: [Fake News Detection](https://github.com/Ujjwal-eng/fake_news_detection)

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- scikit-learn team for excellent ML libraries
- NLTK developers for NLP tools
- Flask community for the lightweight web framework
- Kaggle for providing datasets
- Research papers on fake news detection for inspiration

## üìû Contact & Support

If you have questions or suggestions:
- Open an issue on GitHub
- Fork the project and submit a pull request
- Star ‚≠ê the repository if you find it helpful!

---

**Made with ‚ù§Ô∏è and Python**