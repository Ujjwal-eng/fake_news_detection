# ğŸ” Fake News Detection System

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)](https://flask.palletsprojects.com/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-orange)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

An AI-powered web application that uses Natural Language Processing (NLP) and Machine Learning to detect fake news articles with high accuracy. This project demonstrates end-to-end ML model development, from data preprocessing to web deployment.

## ğŸŒŸ Features

- **ğŸ¤– Ensemble ML Models**: 4 models (Naive Bayes, Random Forest, Logistic Regression, SVM) with majority voting
- **ğŸ” AI Fact-Checker**: Entity verification via Wikipedia, numerical claim validation, scam pattern detection
- **ğŸ§  Advanced NLP**: Text preprocessing with tokenization, stemming, stopword removal, and TF-IDF vectorization
- **ğŸ¨ Modern Web Interface**: Beautiful, responsive Flask-based UI with dark/light themes
- **âš¡ Real-time Analysis**: Instant classification with confidence scores and detailed insights
- **ğŸ“Š Comprehensive Analytics**: Probability distributions, model performance metrics, and fact-check warnings
- **ğŸ›¡ï¸ Input Validation**: Smart edge case handling for URLs, non-English text, and invalid inputs
- **ğŸ§ª Thorough Testing**: Unit tests, model evaluation suite, and edge case analysis

## ğŸ“ Project Structure

```
fake-news-detection/
â”œâ”€â”€ app.py                 # Flask web application
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ .gitignore            # Git ignore rules
â”œâ”€â”€ templates/            # HTML templates
â”‚   â”œâ”€â”€ index.html        # Main page
â”‚   â””â”€â”€ about.html        # About page
â”œâ”€â”€ src/                  # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py # NLP preprocessing utilities
â”‚   â”œâ”€â”€ model.py          # ML model implementation
â”‚   â”œâ”€â”€ fact_checker.py   # AI fact-checking module (NEW!)
â”‚   â””â”€â”€ utils.py          # Helper functions
â”œâ”€â”€ data/                 # Dataset storage
â”‚   â”œâ”€â”€ raw/              # Raw datasets
â”‚   â”œâ”€â”€ processed/        # Processed datasets
â”‚   â””â”€â”€ sample_data.csv   # Sample dataset
â”œâ”€â”€ models/               # Trained models
â”‚   â”œâ”€â”€ naive_bayes_model.joblib
â”‚   â”œâ”€â”€ vectorizer.joblib
â”‚   â””â”€â”€ training_results.txt
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â””â”€â”€ text_processing_basics.ipynb
â””â”€â”€ tests/                # Unit tests
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_model.py
```

## ğŸš€ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Git (for cloning)

### Step 1: Clone the Repository
```bash
git clone https://github.com/Ujjwal-eng/fake_news_detection.git
cd fake_news_detection
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Download Required NLTK Data
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('omw-1.4')"
```

## ğŸ’» Usage

### Running the Web Application
```bash
python app.py
```
Then open your browser and navigate to: `http://localhost:5000`

### Training Models
To train new models with your own dataset:
```bash
# Place your dataset in data/raw/
# Then run the training script
python -m src.model
```

### Using Jupyter Notebooks
For experimentation and analysis:
```bash
jupyter notebook
# Open notebooks/ directory
```

## ğŸ“Š Dataset

### Training Data Coverage (2016-2023)
The models are trained on **11,632 professionally labeled articles** spanning multiple years and contexts:

- **2016-2017**: Political news from ISOT Fake News Dataset (5,816 articles)
- **2020-2021**: COVID-19 misinformation and health news (3,581 articles)
- **2022-2023**: Recent fake news from diverse sources (6,299 articles)

**Dataset Composition:**
- Real News: 5,816 articles (50%)
- Fake News: 5,816 articles (50%)
- Total: 11,632 perfectly balanced articles

### Why 2016-2023?
Labeled fake news datasets require:
- âœ… Professional fact-checking (6-12 months)
- âœ… Expert verification from multiple sources
- âœ… Legal review to avoid defamation
- âœ… Consensus from fact-checking organizations

This makes 2016-2023 the most recent professionally verified data available for training.

### Required Format
```csv
text,label
"News article text here...",0
"Another news article...",1
```

- **text**: The news article content (string)
- **label**: 0 for real news, 1 for fake news (integer)

## ğŸ¯ Model Performance

Trained on **11,632 balanced articles (2016-2023)**:

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Naive Bayes | 83.2% | 83.7% | 83.2% | 83.1% |
| Logistic Regression | 90.0% | 90.0% | 90.0% | 90.0% |
| Random Forest | 87.8% | 87.9% | 87.8% | 87.8% |
| SVM | 89.7% | 89.7% | 89.7% | 89.7% |

**Ensemble Voting System:** Combines all 4 models with majority voting and confidence-based tie-breaking for optimal accuracy.

### Dataset Sources
- **ISOT Fake News Dataset**: 44,898 political articles (2016-2017) from Kaggle
- **COVID-19 Fake News Dataset**: 10,700 health-related articles (2020-2021)
- **Recent Fake News Dataset**: 6,335 diverse articles (2022-2023)

*Final training set: 11,632 articles after deduplication and balancing*

## ğŸ› ï¸ Technologies Used

### Core Technologies
- **Python 3.8+**: Primary programming language
- **Flask**: Web framework for the application
- **scikit-learn**: Machine learning models and evaluation
- **NLTK**: Natural language processing toolkit
- **Pandas & NumPy**: Data manipulation and analysis
- **Joblib**: Model serialization

### Machine Learning
- Naive Bayes Classifier
- Random Forest Classifier
- Logistic Regression
- Support Vector Machine (SVM)
- TF-IDF Vectorization

### Frontend
- HTML5 & CSS3
- JavaScript (Vanilla)
- Responsive Design

## ğŸ§  How It Works

### 1. Text Preprocessing Pipeline
```
Raw Text â†’ Lowercasing â†’ Tokenization â†’ Stop Word Removal â†’ Stemming â†’ Clean Text
```

### 2. Feature Extraction
- **TF-IDF Vectorization**: Converts text to numerical features
- **N-gram Analysis**: Captures word patterns (unigrams, bigrams)
- **Feature Selection**: Identifies most informative features

### 3. Classification
- Multiple ML models trained on labeled datasets
- Ensemble predictions for improved accuracy
- Probability estimation for confidence scoring

### 4. Web Interface
- User submits news text
- Backend processes and vectorizes text
- Model predicts and returns result with confidence

## ğŸ“ Key Learnings & Skills Demonstrated

- âœ… End-to-end ML project development
- âœ… Natural Language Processing techniques
- âœ… Model training, evaluation, and optimization
- âœ… Web application development with Flask
- âœ… RESTful API design
- âœ… Version control with Git/GitHub
- âœ… Code organization and best practices

## ğŸ“¸ Screenshots

### Home Page
Clean and intuitive interface for news analysis

### Results Page
Detailed prediction with confidence scores and probabilities

## ğŸ”® Future Enhancements

- [ ] Deep learning models (LSTM, BERT, Transformers)
- [ ] Multi-language support (Hindi, Spanish, etc.)
- [ ] Source credibility analysis
- [ ] Real-time news monitoring and alerts
- [ ] Browser extension for instant verification
- [ ] Mobile application (iOS/Android)
- [ ] Integration with fact-checking APIs (Alt News, BOOM Live)
- [ ] User authentication and history tracking
- [ ] Temporal model updates with 2024+ data as it becomes available

## âš ï¸ Disclaimer & Limitations

### Use Responsibly
This system is designed as an **educational tool and ML demonstration project**. It should not be used as the sole method for verifying news authenticity.

### Two-Layer Detection System

#### Layer 1: Machine Learning Models
The models analyze **writing patterns and linguistic features**:
- âœ… Sensational language and emotional manipulation
- âœ… Conspiracy theory rhetoric patterns
- âœ… Poor grammar and structure (common in low-quality fake news)
- âœ… Clickbait-style headlines
- âœ… Absence of proper attribution and sources
- âœ… Vague or missing details

#### Layer 2: AI Fact-Checker (NEW!)
The fact-checker performs **content verification and claim validation**:
- âœ… **Entity Verification**: Cross-references organizations, locations, and infrastructure with Wikipedia
- âœ… **Numerical Validation**: Detects unrealistic claims (impossible percentages, distances, speeds)
- âœ… **Scam Pattern Detection**: Identifies viral message patterns ("forward this", "share urgently")
- âœ… **Confidence Override**: Automatically flags articles with verifiable false claims as FAKE

**How it works**: If the fact-checker detects contradictions (e.g., non-existent metro lines, impossible statistics), it **overrides the ML prediction** and classifies the article as FAKE NEWS, even if the writing style appears professional.

### What the System CANNOT Detect
Despite the dual-layer approach, some limitations remain:
- âŒ Cannot verify very recent events not yet documented on Wikipedia
- âŒ Cannot access paywalled sources or private databases
- âŒ Limited to English language content
- âŒ Cannot verify claims requiring real-time data or government databases

**Example**: A fake news article about a non-existent Delhi Metro line, written in professional journalistic style with specific details, would be misclassified as REAL because it matches the writing patterns of legitimate news. The models detect patterns, not facts.

**Solution**: For production systems, combine these ML models with:
1. Fact-checking APIs (Alt News, BOOM Live, Snopes)
2. Knowledge graphs (Wikipedia, Wikidata)
3. Government database integration
4. Source credibility analysis

See [MODEL_LIMITATIONS.md](MODEL_LIMITATIONS.md) for detailed analysis.

### Temporal Limitations
- **Training Period**: 2016-2023 (most recent professionally labeled data)
- **Performance**: Optimized for news from the training period
- **Modern Terms**: May have limited exposure to very recent terminology (2024-2025 specific events/technologies)

### Best Practices
Always:
- âœ… Cross-reference with multiple reliable sources
- âœ… Check the original source's credibility and reputation
- âœ… Consider the context, date, and author of publication
- âœ… Consult professional fact-checkers for important decisions
- âœ… Verify through established fact-checking organizations

### Real-World Context
This project demonstrates understanding of:
- Data labeling challenges in ML
- Temporal dataset drift and model limitations
- Professional ML project development
- Real-world constraints in fake news detection

## ğŸ‘¨â€ğŸ’» Author

**Ujjwal Bansal**
- GitHub: [@Ujjwal-eng](https://github.com/Ujjwal-eng)
- Project: [Fake News Detection](https://github.com/Ujjwal-eng/fake_news_detection)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- scikit-learn team for excellent ML libraries
- NLTK developers for NLP tools
- Flask community for the lightweight web framework
- Kaggle for providing datasets
- Research papers on fake news detection for inspiration

## ğŸ“ Contact & Support

If you have questions or suggestions:
- Open an issue on GitHub
- Fork the project and submit a pull request
- Star â­ the repository if you find it helpful!

---

**Made with â¤ï¸ and Python**